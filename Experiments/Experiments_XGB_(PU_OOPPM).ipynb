{"cells":[{"cell_type":"markdown","metadata":{"id":"wLz0ql-Mcyw6"},"source":["##############################################\n","\n","############# TABLE OF CONTENTS #############\n","\n","##############################################\n","- 1) Import packages and functions\n","- 2) Function for preprocessing the data\n","- 3) Parameters"]},{"cell_type":"code","source":["incomplete_levels = ['00', '25', '50', '75']"],"metadata":{"id":"2bwY9DoevNKF","executionInfo":{"status":"ok","timestamp":1660463690132,"user_tz":-120,"elapsed":836,"user":{"displayName":"Jari Peeperkorn","userId":"01230011772246216346"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DKrN-KdOvN2R","executionInfo":{"status":"ok","timestamp":1660463714128,"user_tz":-120,"elapsed":23469,"user":{"displayName":"Jari Peeperkorn","userId":"01230011772246216346"}},"outputId":"8d9ecc80-c267-47f0-a5b2-7c2493146e96"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"v0yRQ_ZSMaFG"},"source":["# **import packages and functions**"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"uwBik9AUO-VZ","executionInfo":{"status":"ok","timestamp":1660463715080,"user_tz":-120,"elapsed":955,"user":{"displayName":"Jari Peeperkorn","userId":"01230011772246216346"}}},"outputs":[],"source":["# functions and packages\n","from scipy.spatial import distance\n","from sklearn.metrics import roc_curve\n","import random\n","import time\n","from sklearn.preprocessing import MinMaxScaler\n","\n","\n","import xgboost as xgb\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.pipeline import FeatureUnion\n","from sklearn.metrics import roc_auc_score, accuracy_score\n","import numpy as np\n","import pandas as pd\n","import pickle\n","import os\n","# import packages\n","# packages from https://github.com/irhete/predictive-monitoring-benchmark/blob/master/experiments/experiments.py\n","\n","import EncoderFactory\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","pd.options.mode.chained_assignment = None"]},{"cell_type":"markdown","metadata":{"id":"ud8f9rgWcyxI"},"source":["## Functions from stackoverflow"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"uH3LRIBHOyap","executionInfo":{"status":"ok","timestamp":1660463715080,"user_tz":-120,"elapsed":3,"user":{"displayName":"Jari Peeperkorn","userId":"01230011772246216346"}}},"outputs":[],"source":["def transform_data(dt_train, dt_test, y_train):\n","    # feature combiner and columns\n","    feature_combiner = FeatureUnion([(method, EncoderFactory.get_encoder(\n","          method, **cls_encoder_args)) for method in methods])\n","    feature_combiner.fit(dt_train, y_train)\n","\n","    # transform train dataset and add the column names back to the dataframe\n","    train_named = feature_combiner.transform(dt_train)\n","    train_named = pd.DataFrame(train_named)\n","    names = feature_combiner.get_feature_names()\n","    train_named.columns = names\n","\n","    # transform test dataset\n","    test_named = feature_combiner.transform(dt_test)\n","    test_named = pd.DataFrame(test_named)\n","    names = feature_combiner.get_feature_names()\n","    test_named.columns = names\n","\n","    return train_named, test_named"]},{"cell_type":"markdown","metadata":{"id":"dkzXHGIWjOVO"},"source":["# Function to flip labels"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"u8xAQSa9jNub","executionInfo":{"status":"ok","timestamp":1660463715081,"user_tz":-120,"elapsed":3,"user":{"displayName":"Jari Peeperkorn","userId":"01230011772246216346"}}},"outputs":[],"source":["def count_labels(data_y):\n","    print(\"total size\", len(data_y))\n","    #print(\"regular\", data_y.count(\"regular\"))\n","    #print(\"deviant\", data_y.count(\"deviant\"))\n","\n","def count_labels_number(data_y):\n","    print(\"total size\", len(data_y))\n","    #print(\"regular\", data_y.count(0))\n","    #print(\"deviant\", data_y.count(1))"]},{"cell_type":"code","source":["import sys\n","\n","import dataset_confs\n","\n","import pandas as pd\n","import numpy as np\n","\n","from sklearn.model_selection import StratifiedKFold\n","\n","\n","class DatasetManager:\n","    \n","    def __init__(self, dataset_name):\n","        self.dataset_name = dataset_name\n","        \n","        self.case_id_col = dataset_confs.case_id_col[self.dataset_name]\n","        self.activity_col = dataset_confs.activity_col[self.dataset_name]\n","        self.timestamp_col = dataset_confs.timestamp_col[self.dataset_name]\n","        self.label_col = dataset_confs.label_col[self.dataset_name]\n","        self.pos_label = dataset_confs.pos_label[self.dataset_name]\n","\n","        self.dynamic_cat_cols = dataset_confs.dynamic_cat_cols[self.dataset_name]\n","        self.static_cat_cols = dataset_confs.static_cat_cols[self.dataset_name]\n","        self.dynamic_num_cols = dataset_confs.dynamic_num_cols[self.dataset_name]\n","        self.static_num_cols = dataset_confs.static_num_cols[self.dataset_name]\n","        \n","        self.sorting_cols = [self.timestamp_col, self.activity_col]\n","\n","    \n","    def read_dataset(self, datalocation):\n","        # read dataset\n","        dtypes = {col:\"object\" for col in self.dynamic_cat_cols+self.static_cat_cols+[self.case_id_col, self.label_col, self.timestamp_col]}\n","        for col in self.dynamic_num_cols + self.static_num_cols:\n","            dtypes[col] = \"float\"\n","\n","        data = pd.read_csv(datalocation, sep=\";\", dtype=dtypes)\n","        data[self.timestamp_col] = pd.to_datetime(data[self.timestamp_col])\n","\n","        if self.dataset_name in ['bpic2011_f1', 'bpic2011_f2', 'bpic2011_f3', 'bpic2011_f4','bpic2015_1_f2','bpic2015_2_f2','bpic2015_3_f2','bpic2015_4_f2','bpic2015_5_f2','sepsis_cases_1','sepsis_cases_2','sepsis_cases_4']:\n","            data['time:timestamp'] = pd.to_datetime(data['time:timestamp']) \n","        if self.dataset_name in ['bpic2012_accepted', 'bpic2012_cancelled', 'bpic2012_declined']:\n","            data['Complete Timestamp'] = pd.to_datetime(data['Complete Timestamp'])\n","\n","        return data\n","    \n","\n","\n","    def split_data(self, data, train_ratio, split=\"temporal\", seed=22):  \n","        # split into train and test using temporal split\n","\n","        grouped = data.groupby(self.case_id_col)\n","        start_timestamps = grouped[self.timestamp_col].min().reset_index()\n","        if split == \"temporal\":\n","            start_timestamps = start_timestamps.sort_values(self.timestamp_col, ascending=True, kind=\"mergesort\")\n","        elif split == \"random\":\n","            np.random.seed(seed)\n","            start_timestamps = start_timestamps.reindex(np.random.permutation(start_timestamps.index))\n","        train_ids = list(start_timestamps[self.case_id_col])[:int(train_ratio*len(start_timestamps))]\n","        train = data[data[self.case_id_col].isin(train_ids)].sort_values(self.timestamp_col, ascending=True, kind='mergesort')\n","        test = data[~data[self.case_id_col].isin(train_ids)].sort_values(self.timestamp_col, ascending=True, kind='mergesort')\n","\n","        return (train, test)\n","    \n","    def split_data_strict(self, data, train_ratio, split=\"temporal\"):  \n","        # split into train and test using temporal split and discard events that overlap the periods\n","        data = data.sort_values(self.sorting_cols, ascending=True, kind='mergesort')\n","        grouped = data.groupby(self.case_id_col)\n","        start_timestamps = grouped[self.timestamp_col].min().reset_index()\n","        start_timestamps = start_timestamps.sort_values(self.timestamp_col, ascending=True, kind='mergesort')\n","        train_ids = list(start_timestamps[self.case_id_col])[:int(train_ratio*len(start_timestamps))]\n","        train = data[data[self.case_id_col].isin(train_ids)].sort_values(self.sorting_cols, ascending=True, kind='mergesort')\n","        test = data[~data[self.case_id_col].isin(train_ids)].sort_values(self.sorting_cols, ascending=True, kind='mergesort')\n","        split_ts = test[self.timestamp_col].min()\n","        train = train[train[self.timestamp_col] < split_ts]\n","        return (train, test)\n","    \n","    def split_data_discard(self, data, train_ratio, split=\"temporal\"):  \n","        # split into train and test using temporal split and discard events that overlap the periods\n","        data = data.sort_values(self.sorting_cols, ascending=True, kind='mergesort')\n","        grouped = data.groupby(self.case_id_col)\n","        start_timestamps = grouped[self.timestamp_col].min().reset_index()\n","        start_timestamps = start_timestamps.sort_values(self.timestamp_col, ascending=True, kind='mergesort')\n","        train_ids = list(start_timestamps[self.case_id_col])[:int(train_ratio*len(start_timestamps))]\n","        train = data[data[self.case_id_col].isin(train_ids)].sort_values(self.sorting_cols, ascending=True, kind='mergesort')\n","        test = data[~data[self.case_id_col].isin(train_ids)].sort_values(self.sorting_cols, ascending=True, kind='mergesort')\n","        split_ts = test[self.timestamp_col].min()\n","        overlapping_cases = train[train[self.timestamp_col] >= split_ts][self.case_id_col].unique()\n","        train = train[~train[self.case_id_col].isin(overlapping_cases)]\n","        return (train, test)\n","    \n","    \n","    def split_val(self, data, val_ratio, split=\"random\", seed=22):  \n","        # split into train and test using temporal split\n","        grouped = data.groupby(self.case_id_col)\n","        start_timestamps = grouped[self.timestamp_col].min().reset_index()\n","        if split == \"temporal\":\n","            start_timestamps = start_timestamps.sort_values(self.timestamp_col, ascending=True, kind=\"mergesort\")\n","        elif split == \"random\":\n","            np.random.seed(seed)\n","            start_timestamps = start_timestamps.reindex(np.random.permutation(start_timestamps.index))\n","        val_ids = list(start_timestamps[self.case_id_col])[-int(val_ratio*len(start_timestamps)):]\n","        val = data[data[self.case_id_col].isin(val_ids)].sort_values(self.sorting_cols, ascending=True, kind=\"mergesort\")\n","        train = data[~data[self.case_id_col].isin(val_ids)].sort_values(self.sorting_cols, ascending=True, kind=\"mergesort\")\n","        return (train, val)\n","\n","\n","    def generate_prefix_data(self, data, min_length, max_length, gap=1):\n","        # generate prefix data (each possible prefix becomes a trace)\n","        data['case_length'] = data.groupby(self.case_id_col)[self.activity_col].transform(len)\n","\n","        dt_prefixes = data[data['case_length'] >= min_length].groupby(self.case_id_col).head(min_length)\n","        dt_prefixes[\"prefix_nr\"] = 1\n","        dt_prefixes[\"orig_case_id\"] = dt_prefixes[self.case_id_col]\n","        for nr_events in range(min_length+gap, max_length+1, gap):\n","            tmp = data[data['case_length'] >= nr_events].groupby(self.case_id_col).head(nr_events)\n","            tmp[\"orig_case_id\"] = tmp[self.case_id_col]\n","            tmp[self.case_id_col] = tmp[self.case_id_col].apply(lambda x: \"%s_%s\"%(x, nr_events))\n","            tmp[\"prefix_nr\"] = nr_events\n","            dt_prefixes = pd.concat([dt_prefixes, tmp], axis=0)\n","        \n","        dt_prefixes['case_length'] = dt_prefixes['case_length'].apply(lambda x: min(max_length, x))\n","        \n","        return dt_prefixes\n","\n","\n","    def get_pos_case_length_quantile(self, data, quantile=0.90):\n","        return int(np.ceil(data[data[self.label_col]==self.pos_label].groupby(self.case_id_col).size().quantile(quantile)))\n","\n","    def get_indexes(self, data):\n","        return data.groupby(self.case_id_col).first().index\n","\n","    def get_relevant_data_by_indexes(self, data, indexes):\n","        return data[data[self.case_id_col].isin(indexes)]\n","\n","    def get_label(self, data):\n","        return data.groupby(self.case_id_col).first()[self.label_col]\n","    \n","    def get_prefix_lengths(self, data):\n","        return data.groupby(self.case_id_col).last()[\"prefix_nr\"]\n","    \n","    def get_case_ids(self, data, nr_events=1):\n","        case_ids = pd.Series(data.groupby(self.case_id_col).first().index)\n","        if nr_events > 1:\n","            case_ids = case_ids.apply(lambda x: \"_\".join(x.split(\"_\")[:-1]))\n","        return case_ids\n","    \n","    def get_label_numeric(self, data):\n","        y = self.get_label(data) # one row per case\n","        return [1 if label == self.pos_label else 0 for label in y]\n","    \n","    def get_class_ratio(self, data):\n","        class_freqs = data[self.label_col].value_counts()\n","        return class_freqs[self.pos_label] / class_freqs.sum()\n","    \n","    def get_stratified_split_generator(self, data, n_splits=5, shuffle=True, random_state=22):\n","        grouped_firsts = data.groupby(self.case_id_col, as_index=False).first()\n","        skf = StratifiedKFold(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n","        \n","        for train_index, test_index in skf.split(grouped_firsts, grouped_firsts[self.label_col]):\n","            current_train_names = grouped_firsts[self.case_id_col][train_index]\n","            train_chunk = data[data[self.case_id_col].isin(current_train_names)].sort_values(self.timestamp_col, ascending=True, kind='mergesort')\n","            test_chunk = data[~data[self.case_id_col].isin(current_train_names)].sort_values(self.timestamp_col, ascending=True, kind='mergesort')\n","            yield (train_chunk, test_chunk)\n","            \n","    def get_idx_split_generator(self, dt_for_splitting, n_splits=5, shuffle=True, random_state=22):\n","        skf = StratifiedKFold(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n","        \n","        for train_index, test_index in skf.split(dt_for_splitting, dt_for_splitting[self.label_col]):\n","            current_train_names = dt_for_splitting[self.case_id_col][train_index]\n","            current_test_names = dt_for_splitting[self.case_id_col][test_index]\n","            yield (current_train_names, current_test_names)\n","            "],"metadata":{"id":"owiiRk-gvKlr","executionInfo":{"status":"ok","timestamp":1660463715455,"user_tz":-120,"elapsed":377,"user":{"displayName":"Jari Peeperkorn","userId":"01230011772246216346"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HcKLuejWcyxN"},"source":["# Parameters"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"ufibRgR8cyxO","executionInfo":{"status":"ok","timestamp":1660463715455,"user_tz":-120,"elapsed":3,"user":{"displayName":"Jari Peeperkorn","userId":"01230011772246216346"}}},"outputs":[],"source":["# PARAMETERS\n","params_dir = './params_dir_ML'\n","results_dir = './results_dir_ML'\n","column_selection = 'all'\n","train_ratio = 0.8\n","n_splits = 3\n","random_state = 22\n","n_iter = 1\n","\n","# create results directory\n","if not os.path.exists(os.path.join(results_dir)):\n","    os.makedirs(os.path.join(results_dir))\n","\n","encoding_dict = {\n","    \"agg\": [\"static\", \"agg\"],\n","    # \"index\": [\"static\", \"index\"]\n","}\n","encoding = []\n","for k, v in encoding_dict.items():\n","    encoding.append(k)\n","\n","csv_files = {\n","    \"bpic2011\": [\"BPIC11_f%s\"%formula for formula in range(4,5)],\n","    \"bpic2015\": [\"BPIC15_%s_f2\"%(municipality) for municipality in range(1,4)],\n","    #\"sepsis_cases\": [\"sepsis_cases_1\", \"sepsis_cases_2\", \"sepsis_cases_4\"],\n","    #\"bpic2012\": [\"bpic2012_O_ACCEPTED#COMPLETE\",\"bpic2012_O_CANCELLED-COMPLETE\",\"bpic2012_0_DECLINED-COMPLETE\"],\n","    #production\": [\"Production\"],\n","    #\"bpic2017\": [\"BPIC17_O_Accepted\",\"BPIC17_O_Cancelled\",\"BPIC17_0_Refused\"],\n","    #\"bpic2017\": [\"BPIC17_O_Cancelled\"],\n","    #\"traffic_fines\": [\"traffic_fines_%s\"%formula for formula in range(1,3)],\n","    #\"hospital_billing\": [\"hospital_billing_%s\"%suffix for suffix in [2,3]]\n","}\n","files = []\n","for k, v in csv_files.items():\n","    files.extend(v)\n","dataset_ref_to_datasets = {\n","    \"bpic2011\": [\"bpic2011_f%s\"%formula for formula in range(4,5)],\n","    \"bpic2015\": [\"bpic2015_%s_f2\"%(municipality) for municipality in range(1,4)],\n","    #\"sepsis_cases\": [\"sepsis_cases_1\", \"sepsis_cases_2\", \"sepsis_cases_4\"]\n","    #\"bpic2012\": [\"bpic2012_accepted\",\"bpic2012_cancelled\",\"bpic2012_declined\"],\n","    #\"production\": [\"production\"],\n","    #\"bpic2017\": [\"bpic2017_cancelled\"],\n","    #\"bpic2017\": [\"bpic2017_accepted\",\"bpic2017_cancelled\",\"bpic2017_refused\"],\n","    #\"traffic_fines\": [\"traffic_fines_%s\"%formula for formula in range(1,3)],\n","    #\"hospital_billing\": [\"hospital_billing_%s\"%suffix for suffix in [2,3]]\n","}\n","\n","files = []\n","for k, v in csv_files.items():\n","    files.extend(v)\n","datasets = []\n","for k, v in dataset_ref_to_datasets.items():\n","    datasets.extend(v)\n","res = {datasets[i]: files[i] for i in range(len(datasets))}\n","\n","# classifiers dictionary\n","classifier_ref_to_classifiers = {\n","     \"MLmodels\": [\"XGB\"],\n","   }\n","classifiers = []\n","for k, v in classifier_ref_to_classifiers.items():\n","    classifiers.extend(v)\n","incomplete_levels = ['00', '25', '50', '75']"]},{"cell_type":"markdown","metadata":{"id":"PVX1WhP2Mvv-"},"source":["# **loop over datasets and classifiers**"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"agyg5xxq09yo","outputId":"631ac90e-2903-4b0b-87cc-8fc97effd0a3","executionInfo":{"status":"ok","timestamp":1660470153855,"user_tz":-120,"elapsed":6438402,"user":{"displayName":"Jari Peeperkorn","userId":"01230011772246216346"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset: bpic2011_f4\n","Classifier XGB\n","Encoding agg\n","{'colsample_bytree': 0.6456099376490885, 'learning_rate': 0.0328658836622191, 'max_depth': 17, 'min_child_weight': 6, 'subsample': 0.9560784753132745}\n","total size 21902\n","total size 7491\n","0.8652857322227787\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_c2c87482-69be-4b55-925b-43813723df2c\", \"performance_results_XGB_bpic2011_f4_00_all_agg.csv\", 2196)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset: bpic2011_f4\n","Classifier XGB\n","Encoding agg\n","{'colsample_bytree': 0.9747371891675085, 'learning_rate': 0.011089509060744018, 'max_depth': 22, 'min_child_weight': 5, 'subsample': 0.7768664011411401}\n","total size 21902\n","total size 7491\n","0.8550003085297818\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_da77ce6d-604d-490b-ae13-b1cbc288225c\", \"performance_results_XGB_bpic2011_f4_25_all_agg.csv\", 2197)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset: bpic2011_f4\n","Classifier XGB\n","Encoding agg\n","{'colsample_bytree': 0.9224852779417818, 'learning_rate': 0.15536730191157233, 'max_depth': 23, 'min_child_weight': 4, 'subsample': 0.508197961285134}\n","total size 21902\n","total size 7491\n","0.8136121120631707\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_ebf3ee68-c454-4821-9675-596e049ec676\", \"performance_results_XGB_bpic2011_f4_50_all_agg.csv\", 2201)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset: bpic2011_f4\n","Classifier XGB\n","Encoding agg\n","{'colsample_bytree': 0.5249164443878849, 'learning_rate': 0.14712433401218095, 'max_depth': 19, 'min_child_weight': 4, 'subsample': 0.9322228144336675}\n","total size 21902\n","total size 7491\n","0.7205410968112052\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_ed916ec9-ac39-4d4f-b6d9-3b04d67af725\", \"performance_results_XGB_bpic2011_f4_75_all_agg.csv\", 2198)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset: bpic2015_1_f2\n","Classifier XGB\n","Encoding agg\n","{'colsample_bytree': 0.9346091294700718, 'learning_rate': 0.04045200563382756, 'max_depth': 28, 'min_child_weight': 3, 'subsample': 0.6639032370830285}\n","total size 18345\n","total size 4876\n","0.9175938261029121\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_dc418c88-99e7-4328-b080-7f33c6b71a37\", \"performance_results_XGB_bpic2015_1_f2_00_all_agg.csv\", 2174)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset: bpic2015_1_f2\n","Classifier XGB\n","Encoding agg\n","{'colsample_bytree': 0.5033332972450442, 'learning_rate': 0.012333759007818967, 'max_depth': 23, 'min_child_weight': 5, 'subsample': 0.795416567381228}\n","total size 18345\n","total size 4876\n","0.9194024357274774\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_ae57f007-715a-4ffe-9a95-911d13950848\", \"performance_results_XGB_bpic2015_1_f2_25_all_agg.csv\", 2183)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset: bpic2015_1_f2\n","Classifier XGB\n","Encoding agg\n","{'colsample_bytree': 0.6853530947220043, 'learning_rate': 0.304677988480315, 'max_depth': 17, 'min_child_weight': 2, 'subsample': 0.7834627111709327}\n","total size 18345\n","total size 4876\n","0.9040597629416344\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_b36d54de-8862-4ddb-9f36-1a487542b4ab\", \"performance_results_XGB_bpic2015_1_f2_50_all_agg.csv\", 2135)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset: bpic2015_1_f2\n","Classifier XGB\n","Encoding agg\n","{'colsample_bytree': 0.7606251756319556, 'learning_rate': 0.0011458843445060207, 'max_depth': 22, 'min_child_weight': 3, 'subsample': 0.8667085427407879}\n","total size 18345\n","total size 4876\n","0.7618649156007508\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_89b9bef0-44a0-45d2-a4a9-124facbd87bd\", \"performance_results_XGB_bpic2015_1_f2_75_all_agg.csv\", 2275)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset: bpic2015_2_f2\n","Classifier XGB\n","Encoding agg\n","{'colsample_bytree': 0.6563490128331088, 'learning_rate': 0.17540886525849986, 'max_depth': 24, 'min_child_weight': 4, 'subsample': 0.6948134652058899}\n","total size 22221\n","total size 5789\n","0.9472852562759042\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_5a46bd27-17d6-4461-995c-8f7ad4221b8e\", \"performance_results_XGB_bpic2015_2_f2_00_all_agg.csv\", 2236)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset: bpic2015_2_f2\n","Classifier XGB\n","Encoding agg\n","{'colsample_bytree': 0.6662850106503915, 'learning_rate': 0.050503104929724096, 'max_depth': 18, 'min_child_weight': 4, 'subsample': 0.9220500938117628}\n","total size 22221\n","total size 5789\n","0.9529500023551792\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_bb3480e5-2139-4c80-b2e2-06a8535e1857\", \"performance_results_XGB_bpic2015_2_f2_25_all_agg.csv\", 2262)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset: bpic2015_2_f2\n","Classifier XGB\n","Encoding agg\n","{'colsample_bytree': 0.6780879169305561, 'learning_rate': 0.03937952355109364, 'max_depth': 15, 'min_child_weight': 4, 'subsample': 0.8439683615191149}\n","total size 22221\n","total size 5789\n","0.9149933730876053\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_a213aed7-870a-4af0-b1f3-cad948dddcc3\", \"performance_results_XGB_bpic2015_2_f2_50_all_agg.csv\", 2221)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset: bpic2015_2_f2\n","Classifier XGB\n","Encoding agg\n","{'colsample_bytree': 0.6320642022815781, 'learning_rate': 0.020401364008479916, 'max_depth': 15, 'min_child_weight': 2, 'subsample': 0.5059281587475952}\n","total size 22221\n","total size 5789\n","0.9097082646045958\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_1c7d34e9-ccf7-448b-a65a-c918c49515e0\", \"performance_results_XGB_bpic2015_2_f2_75_all_agg.csv\", 2252)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset: bpic2015_3_f2\n","Classifier XGB\n","Encoding agg\n","{'colsample_bytree': 0.807530409018419, 'learning_rate': 0.053351866886983124, 'max_depth': 4, 'min_child_weight': 5, 'subsample': 0.8787421775126139}\n","total size 37400\n","total size 10041\n","0.9625274600830885\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_b21b7019-a7b2-46c0-96d6-a016add9f7e3\", \"performance_results_XGB_bpic2015_3_f2_00_all_agg.csv\", 2279)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset: bpic2015_3_f2\n","Classifier XGB\n","Encoding agg\n","{'colsample_bytree': 0.8211704176073136, 'learning_rate': 0.15463959216079115, 'max_depth': 18, 'min_child_weight': 3, 'subsample': 0.9664162632101461}\n","total size 37400\n","total size 10041\n","0.9410364907632327\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_ba54cc45-398d-464f-84a7-dae63c5bb38b\", \"performance_results_XGB_bpic2015_3_f2_25_all_agg.csv\", 2282)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset: bpic2015_3_f2\n","Classifier XGB\n","Encoding agg\n","{'colsample_bytree': 0.8490469694021753, 'learning_rate': 0.041587254117149586, 'max_depth': 16, 'min_child_weight': 3, 'subsample': 0.5737684721404155}\n","total size 37400\n","total size 10041\n","0.9423060349628032\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_6afddb40-cf9f-4dd7-b6d5-3ae0c3c9fdb4\", \"performance_results_XGB_bpic2015_3_f2_50_all_agg.csv\", 2283)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset: bpic2015_3_f2\n","Classifier XGB\n","Encoding agg\n","{'colsample_bytree': 0.7114591941259321, 'learning_rate': 0.009674548119496529, 'max_depth': 12, 'min_child_weight': 3, 'subsample': 0.7806593413631935}\n","total size 37400\n","total size 10041\n","0.9302066066154835\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_81eb091e-406b-4d43-86ee-e8c79d247fb3\", \"performance_results_XGB_bpic2015_3_f2_75_all_agg.csv\", 2282)"]},"metadata":{}}],"source":["for dataset_name in datasets:\n","  for cls_method in classifiers:\n","    for cls_encoding in encoding:\n","        for level in incomplete_levels: \n","            print('Dataset:', dataset_name)\n","            print('Classifier', cls_method)\n","            print('Encoding', cls_encoding)\n","            dataset_manager = DatasetManager(dataset_name)\n","            dataset_name_csv = res[dataset_name]\n","            data = dataset_manager.read_dataset('/content/drive/MyDrive/PU/Original_data/'+dataset_name_csv+'.csv')\n","            dataset_name_csv = res[dataset_name]\n","            method_name = \"%s_%s\" % (column_selection, cls_encoding)\n","            methods = encoding_dict[cls_encoding]\n","\n","            # extract the optimal parameters\n","            optimal_params_filename = \"optimal_params_%s_%s_%s_%s.pickle\" % (cls_method, dataset_name, level, method_name)\n","            if not os.path.isfile(optimal_params_filename) or os.path.getsize(optimal_params_filename) <= 0:\n","                print('problem')\n","            with open(optimal_params_filename, \"rb\") as fin:\n","                args = pickle.load(fin)\n","                print(args)\n","\n","            cls_encoder_args = {'case_id_col': dataset_manager.case_id_col,\n","                                'static_cat_cols': dataset_manager.static_cat_cols,\n","                                'static_num_cols': dataset_manager.static_num_cols,\n","                                'dynamic_cat_cols': dataset_manager.dynamic_cat_cols,\n","                                'dynamic_num_cols': dataset_manager.dynamic_num_cols,\n","                                'fillna': True}\n","            \n","            #file to save results\n","            outfile = os.path.join('', \"performance_results_%s_%s_%s_%s.csv\" % (cls_method, dataset_name, level, method_name))\n","                \n","            # determine min and max (truncated) prefix lengths\n","            min_prefix_length = 1\n","            if \"traffic_fines\" in dataset_name:\n","                max_prefix_length = 10\n","            elif \"bpic2017\" in dataset_name:\n","                max_prefix_length = min(20, dataset_manager.get_pos_case_length_quantile(data, 0.90))\n","            else:\n","                max_prefix_length = min(40, dataset_manager.get_pos_case_length_quantile(data, 0.90))\n","\n","            maxlen = cutoff = max_prefix_length \n","                \n","            # split into training and test\n","            train = dataset_manager.read_dataset('/content/drive/MyDrive/PU/Data/Train_PU'+level+'_'+dataset_name_csv+'.csv')\n","            test = dataset_manager.read_dataset('/content/drive/MyDrive/PU/Data/Test_'+dataset_name_csv+'.csv')\n","            #prefix generation of train and test data\n","            dt_train_prefixes = dataset_manager.generate_prefix_data(train, min_prefix_length, max_prefix_length)\n","            dt_test_prefixes = dataset_manager.generate_prefix_data(test, min_prefix_length, max_prefix_length)\n","            test_y = dataset_manager.get_label_numeric(dt_test_prefixes)\n","            train_y = dataset_manager.get_label_numeric(dt_train_prefixes)\n","            dt_train_named, dt_test_named = transform_data(dt_train_prefixes, dt_test_prefixes, train_y)\n","          \n","            #DELETE THIS LATER\n","            count_labels_number(train_y)\n","            count_labels_number(test_y)\n","        \n","            #create the input layers and embeddings\n","            embeddings= []\n","            input_layers = []\n","            preds_all = []\n","            nr_events_all = []\n","            nr_events = list(dataset_manager.get_prefix_lengths(dt_test_prefixes))\n","            nr_events_all.extend(nr_events)\n","            test_y_all = []\n","            test_y_all.extend(test_y)\n","            #MODEL\n","            current_args = args\n","            cls = xgb.XGBClassifier(objective='binary:logistic',\n","                                                n_estimators=500,\n","                                                learning_rate= current_args['learning_rate'],\n","                                                subsample=current_args['subsample'],\n","                                                max_depth=int(current_args['max_depth']),\n","                                                colsample_bytree=current_args['colsample_bytree'],\n","                                                min_child_weight=int(current_args['min_child_weight']),\n","                                                seed=random_state)\n","            cls.fit(dt_train_named, train_y)\n","            # predictions\n","            preds_pos_label_idx = np.where(cls.classes_ == 1)[0][0]\n","            pred = cls.predict_proba(dt_test_named)[:, preds_pos_label_idx]\n","            preds_all.extend(pred)\n","            \n","            score = 0\n","            dim = 0\n","            auc_total = roc_auc_score(test_y_all, preds_all)\n","            \n","            print(auc_total)\n","            with open(outfile, 'w') as fout:\n","                fout.write(\"%s;%s;%s;%s;%s;%s\\n\" % (\"dataset\", \"method\", \"cls\", \"nr_events\", \"metric\", \"score\")) \n","                dt_results = pd.DataFrame({\"actual\": test_y_all, \"predicted\": preds_all, \"nr_events\": nr_events_all})\n","                for nr_events, group in dt_results.groupby(\"nr_events\"):\n","                    if len(set(group.actual)) < 2:\n","                        fout.write(\"%s;%s;%s;%s;%s;%s;%s\\n\" % (dataset_name, method_name, cls_method, nr_events, -1,\n","                                                               \"auc\", np.nan))\n","                    else:\n","                        fout.write(\"%s;%s;%s;%s;%s;%s;%s\\n\" % (dataset_name, method_name, cls_method, nr_events, -1,\n","                                                               \"auc\", roc_auc_score(group.actual, group.predicted)))\n","                fout.write(\"%s;%s;%s;%s;%s;%s\\n\" % (dataset_name, method_name, cls_method, -1, \"auc\",\n","                                                    roc_auc_score(dt_results.actual, dt_results.predicted)))\n","            from google.colab import files\n","            files.download(outfile) \n"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"T4SCL-P4E2dt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660470153855,"user_tz":-120,"elapsed":11,"user":{"displayName":"Jari Peeperkorn","userId":"01230011772246216346"}},"outputId":"f6d81137-1283-470f-dc87-426f28404faf"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'colsample_bytree': 0.7114591941259321,\n"," 'learning_rate': 0.009674548119496529,\n"," 'max_depth': 12,\n"," 'min_child_weight': 3,\n"," 'subsample': 0.7806593413631935}"]},"metadata":{},"execution_count":10}],"source":["args"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"MjW9RH8vE2du","executionInfo":{"status":"ok","timestamp":1660470153856,"user_tz":-120,"elapsed":4,"user":{"displayName":"Jari Peeperkorn","userId":"01230011772246216346"}}},"outputs":[],"source":[""]}],"metadata":{"colab":{"collapsed_sections":["v0yRQ_ZSMaFG","UpCBthWhMhkS","HcKLuejWcyxN"],"machine_shape":"hm","name":"Experiments_XGB_(PU_OOPPM).ipynb","provenance":[{"file_id":"1L7CQlk_OxAx5kNRQpZlhDo9W7gOvMcpv","timestamp":1660124158720}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}